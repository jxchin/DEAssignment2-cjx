{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "858ad926",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import json\n",
    "import time\n",
    "import datetime\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "from datetime import date\n",
    "from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e8fd71f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VARIABLES\n",
    "path_to_silver = 'Datalake/silver/'\n",
    "path_to_gold = 'Datalake/gold/'\n",
    "gh_data_staging = 'gh-stg.csv'\n",
    "top_5 = 'top-five.csv'\n",
    "longest_streak = 'longest-streak.csv'\n",
    "heatmap = 'heatmap.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "26b61aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.set_option('display.max_rows', 2500)\n",
    "df = pd.read_csv(path_to_silver+gh_data_staging)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4aecb6",
   "metadata": {},
   "source": [
    "# General Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "83bf28d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1: Cast 'date' col from string to date type\n",
    "df['date'] = pd.to_datetime(df['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "53d1695f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2: Derive Date and Time col \n",
    "df['date_only'] = df['date'].dt.date\n",
    "df['time_only'] = df['date'].dt.time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e84c7a",
   "metadata": {},
   "source": [
    "# Q1 Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6d312e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1: Get total commits by each committer\n",
    "df['commit_count'] = df.groupby(['email'])['email'].transform('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "539a06e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2: Sort by 'commit_count' col in descending order.\n",
    "top5_df = df[['email','commit_count']].sort_values(['commit_count'], ascending=False).drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a90169",
   "metadata": {},
   "source": [
    "# Q1 Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d55815f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save this dataframe as top-five.csv in Gold layer\n",
    "top5_df.to_csv(path_to_gold+top_5, encoding='utf-8', index=False, quoting=csv.QUOTE_ALL, escapechar='\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463b1f99",
   "metadata": {},
   "source": [
    "# Q2 Transformation\n",
    "\n",
    "## Reference: https://stackoverflow.com/questions/52901387/find-group-of-consecutive-dates-in-pandas-dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "8d412b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1: Sort dataframe by email and date\n",
    "longest_streak_df = df.sort_values(['email','date_only'], ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "62855e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2: Keep 1 commit per day per committer\n",
    "longest_streak_df = longest_streak_df[['email','date_only']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "85f049e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3: Check if dates are consecutive by comparing to its previous row and calculate the difference is 1 day. Returns True if consecutive, else False\n",
    "\n",
    "# Compare with previous, next row to check if this is made by same committer and whether it is 1 day apart\n",
    "day = pd.Timedelta('1d')\n",
    "compareUp = (longest_streak_df['email'].eq(longest_streak_df['email'].shift())) & (longest_streak_df['date_only'].diff().abs() == day)\n",
    "compareDown = (longest_streak_df['email'].eq(longest_streak_df['email'].shift(-1))) & (longest_streak_df['date_only'].diff(-1).abs() == day)\n",
    "consecutive = compareUp | compareDown\n",
    "\n",
    "# Save the results\n",
    "longest_streak_df['cmpUp'] = compareUp\n",
    "longest_streak_df['cmpDown'] = compareDown\n",
    "longest_streak_df['consecutive'] = consecutive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "8cd2aa3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4: Identify and Group each occurrence of consecutive commits\n",
    "\n",
    "# Filter consecutive only\n",
    "longest_streak_df = longest_streak_df[longest_streak_df['consecutive'] == True]\n",
    "\n",
    "# Reset row index\n",
    "longest_streak_df = longest_streak_df.reset_index(drop=True)\n",
    "\n",
    "# If cmpUp and cmpDown value changes, it means the streak has broke\n",
    "breakpoint = (longest_streak_df['cmpDown'].ne(longest_streak_df['cmpDown'].shift()) & longest_streak_df['cmpUp'].ne(longest_streak_df['cmpUp'].shift()) ).cumsum()\n",
    "\n",
    "# Add back to longest_streak_df\n",
    "longest_streak_df['streak_grp'] = breakpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "865c6eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5: Derive streak count for each committer for each occurrence\n",
    "longest_streak_df['hot_streak'] = longest_streak_df[longest_streak_df['consecutive']==True].groupby(['email','consecutive','streak_grp'])['streak_grp'].transform('count')\n",
    "longest_streak_df = longest_streak_df[['email','hot_streak']].sort_values(['hot_streak'], ascending=False).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "dd96392c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6: Remove same streaks by same committer on different occurrence\n",
    "longest_streak_df['hot_streak'] = longest_streak_df.groupby(['email'])['hot_streak'].transform('max')\n",
    "longest_streak_df = longest_streak_df.sort_values(['hot_streak'], ascending=False).drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9488ffc8",
   "metadata": {},
   "source": [
    "# Q2 Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "7a98e52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save this dataframe as longest-streak.csv in Gold layer\n",
    "longest_streak_df.to_csv(path_to_gold+longest_streak, encoding='utf-8', index=False, quoting=csv.QUOTE_ALL, escapechar='\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d13d20b",
   "metadata": {},
   "source": [
    "# Q3 Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "2eebb9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User-defined Function\n",
    "# Returns hour block based on row input\n",
    "def label_block(row):\n",
    "    if 0 <= int(row) < 3:\n",
    "        return '00-03'\n",
    "    if 3 <= int(row) < 6:\n",
    "        return '03-06'\n",
    "    if 6 <= int(row) < 9:\n",
    "        return '06-09'\n",
    "    if 9 <= int(row) < 12:\n",
    "        return '09-12'\n",
    "    if 12 <= int(row) < 15:\n",
    "        return '12-15'\n",
    "    if 15 <= int(row) < 18:\n",
    "        return '15-18'\n",
    "    if 18 <= int(row) < 21:\n",
    "        return '18-21'\n",
    "    if 21 <= int(row) < 24:\n",
    "        return '21-00'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "0e517354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intention is to prepare a dataset for PowerBI to display the heatmap along with the above queries\n",
    "\n",
    "heatmap_df = df.sort_values(['date_only','time_only'])\n",
    "# 1: Derive 3-hour block cols and tag Y/N for each rows\n",
    "heatmap_df['hour_of_day'] = df['date'].dt.hour\n",
    "heatmap_df['hour_block'] = heatmap_df['hour_of_day'].apply(label_block)\n",
    "\n",
    "# 2: Derive 'day of week' col\n",
    "heatmap_df['day_of_week'] = df['date'].dt.day_name()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d8ab40",
   "metadata": {},
   "source": [
    "# Q3 Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "3a4b2880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save this dataframe as heatmap.csv in Gold layer\n",
    "heatmap_df[['sha','hour_block','day_of_week']].to_csv(path_to_gold+heatmap, encoding='utf-8', index=False, quoting=csv.QUOTE_ALL, escapechar='\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de877e3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
